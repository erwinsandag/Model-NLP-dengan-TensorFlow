# -*- coding: utf-8 -*-
"""Untitled42.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Or18nSUqrnnxd8JX6Jf1PYG-Pr_geqRi
"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Food_Reviews.csv')

"""Dataset diambil di Google Drive, sebelumnya di download di https://www.kaggle.com/anjaliagrawal12/food-review"""

df.head()

"""Informasi Dataset, yaitu terdiri dari 2 Kolom dan sebanyak 9998 baris/sampel data"""

df.info()

"""Melakukan proses one-hot-encoding, karena data kategorikal"""

category = pd.get_dummies(df.Score)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='Score')
df_baru

"""Mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values"""

reviews = df_baru['Text'].values
score = df_baru[[1, 2, 3]].values

score

"""Membagi data untuk training dan data untuk testing, dimana validasi set 20%"""

from sklearn.model_selection import train_test_split
reviews_latih, reviews_test, score_latih, score_test = train_test_split(reviews, score , test_size=0.2)

"""Merubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer. Setelah tokenisasi selesai, perlu membuat mengonversi setiap sampel menjadi sequence."""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(reviews_latih) 
tokenizer.fit_on_texts(reviews_test)
 
sekuens_latih = tokenizer.texts_to_sequences(reviews_latih)
sekuens_test = tokenizer.texts_to_sequences(reviews_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

"""Model aksitektur menggunakan Layer Embedding, fungsi compile, menentukan optimizer dan menggunakan model loss function dimana model lebih dari 2"""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""Penggunaan fungsi callback, untuk membantu model jika sudah mencapai target >90%"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 23
history = model.fit(padded_latih, score_latih, epochs=num_epochs, callbacks=[callbacks],
                    validation_data=(padded_test, score_test), verbose=2)

"""Plot Loss dan Akurasi pada saat  training dan validasi"""

import matplotlib.pyplot as plt

history_dict = history.history

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss=history_dict['loss']
val_loss=history_dict['val_loss']

epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12,9))
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(12,9))
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.ylim((0.5,1))
plt.show()